<html>
<head>
    <title>Hadoop on OSX</title>
    <meta name="generator" content="DocPad v6.59.6" />
    
</head>
<body>
    <h1>Hadoop on OSX</h1>
<h3>Author: Jonas Colmsjo</h3>
<h3>Date: Fri Mar 01 2013 01:00:00 GMT+0100 (CET)</h3>
<div><p>Hadoop on OSX</p>
<p>Links:</p>
<ul>
<li><a href="http://dennyglee.com/2012/05/08/installing-hadoop-on-osx-lion-10-7/">http://dennyglee.com/2012/05/08/installing-hadoop-on-osx-lion-10-7/</a></li>
</ul>
<h1>Installation</h1>
<p>Summary:</p>
<ul>
<li>Java is needed</li>
<li>XCode is needed</li>
<li>brew is needed (and needs to be healty)  </li>
<li>remote login needs to be enabled</li>
</ul>
<p>Check that java is installed:</p>
<pre><code>Gizur-Laptop-5:cfengine jonas$ java -version
java version &quot;1.6.0_41&quot;
Java(TM) SE Runtime Environment (build 1.6.0_41-b02-445-11M4107)
Java HotSpot(TM) 64-Bit Server VM (build 20.14-b01-445, mixed mode)</code></pre>
<p>Make sure that brew is ok</p>
<pre><code>brew doctor</code></pre>
<p>I always seams to have a lot of errors that I have to clean up. I won&#39;t show this.</p>
<p>Install Hadoop:</p>
<pre><code>brew install hadoop
==&gt; Downloading http://www.apache.org/dyn/closer.cgi?path=hadoop/core/hadoop-1.1.1/hadoop-1.1.1.tar.gz
==&gt; Best Mirror http://apache.mirrors.spacedump.net/hadoop/core/hadoop-1.1.1/hadoop-1.1.1.tar.gz
######################################################################## 100,0%
==&gt; Caveats
In Hadoop&#39;s config file:
  /usr/local/Cellar/hadoop/1.1.1/libexec/conf/hadoop-env.sh
$JAVA_HOME has been set to be the output of:
  /usr/libexec/java_home
==&gt; Summary
üç∫  /usr/local/Cellar/hadoop/1.1.1: 270 files, 75M, built in 113 seconds</code></pre>
<p>/usr/local/Cellar/hadoop/1.1.1/libexec/conf/hadoop-env.sh:</p>
<pre><code>export HADOOP_OPTS=&quot;-Djava.security.krb5.realm=OX.AC.UK -Djava.security.krb5.kdc=kdc0.ox.ac.uk:kdc1.ox.ac.uk&quot;</code></pre>
<p>/usr/local/Cellar/hadoop/1.1.1/libexec/conf/core-site.xml:</p>
<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/Users/${user.name}/hadoop-store&lt;/value&gt;
        &lt;description&gt;A base for other temporary directories.&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;fs.default.name&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:8020&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<p>/usr/local/Cellar/hadoop/1.1.1/libexec/conf/mapred-site.xml:</p>
<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;property&gt;
      &lt;name&gt;mapred.job.tracker&lt;/name&gt;
      &lt;value&gt;localhost:9001&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;mapred.tasktracker.map.tasks.maximum&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;mapred.tasktracker.reduce.tasks.maximum&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<p>/usr/local/Cellar/hadoop/1.1.1/libexec/conf/hdfs-site.xml:</p>
<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;property&gt;
      &lt;name&gt;dfs.replication&lt;/name&gt;
      &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<p>Start hadoop:</p>
<pre><code># Format and then exit
hadoop namenode -format
13/03/01 17:31:31 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = Gizur-Laptop-5.local/10.0.1.117
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.1.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.1 -r 1411108; compiled by &#39;hortonfo&#39; on Mon Nov 19 10:48:11 UTC 2012
************************************************************/
Re-format filesystem in /Users/jonas/hadoop-store/dfs/name ? (Y or N) Y
13/03/01 17:31:37 INFO util.GSet: VM type       = 64-bit
13/03/01 17:31:37 INFO util.GSet: 2% max memory = 19.83375 MB
13/03/01 17:31:37 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/03/01 17:31:37 INFO util.GSet: recommended=2097152, actual=2097152
13/03/01 17:31:37 INFO namenode.FSNamesystem: fsOwner=jonas
13/03/01 17:31:37 INFO namenode.FSNamesystem: supergroup=supergroup
13/03/01 17:31:37 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/03/01 17:31:37 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/03/01 17:31:37 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/03/01 17:31:37 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/03/01 17:31:37 INFO common.Storage: Image file of size 111 saved in 0 seconds.
13/03/01 17:31:37 INFO namenode.FSEditLog: closing edit log: position=4, editlog=/Users/jonas/hadoop-store/dfs/name/current/edits
13/03/01 17:31:37 INFO namenode.FSEditLog: close success: truncate to 4, editlog=/Users/jonas/hadoop-store/dfs/name/current/edits
13/03/01 17:31:37 INFO common.Storage: Storage directory /Users/jonas/hadoop-store/dfs/name has been successfully formatted.
13/03/01 17:31:37 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at Gizur-Laptop-5.local/10.0.1.117
************************************************************/

# Start some
/usr/local/Cellar/hadoop/1.1.1/bin/start-all.sh
Gizur-Laptop-5:dfs jonas$ /usr/local/Cellar/hadoop/1.1.1/bin/start-all.sh
starting namenode, logging to /usr/local/Cellar/hadoop/1.1.1/libexec/bin/../logs/hadoop-jonas-namenode-Gizur-Laptop-5.local.out
Password:
localhost: starting datanode, logging to /usr/local/Cellar/hadoop/1.1.1/libexec/bin/../logs/hadoop-jonas-datanode-Gizur-Laptop-5.local.out
Password:
localhost: starting secondarynamenode, logging to /usr/local/Cellar/hadoop/1.1.1/libexec/bin/../logs/hadoop-jonas-secondarynamenode-Gizur-Laptop-5.local.out
starting jobtracker, logging to /usr/local/Cellar/hadoop/1.1.1/libexec/bin/../logs/hadoop-jonas-jobtracker-Gizur-Laptop-5.local.out
Password:
localhost: starting tasktracker, logging to /usr/local/Cellar/hadoop/1.1.1/libexec/bin/../logs/hadoop-jonas-tasktracker-Gizur-Laptop-5.local.out


# Run example
hadoop jar /usr/local/Cellar/hadoop/1.1.1/libexec/hadoop-examples-1.1.1.jar pi 10 100
Number of Maps  = 10
Samples per Map = 100
Wrote input for Map #0
Wrote input for Map #1
Wrote input for Map #2
Wrote input for Map #3
Wrote input for Map #4
Wrote input for Map #5
Wrote input for Map #6
Wrote input for Map #7
Wrote input for Map #8
Wrote input for Map #9
Starting Job
13/03/01 17:34:38 INFO mapred.FileInputFormat: Total input paths to process : 10
13/03/01 17:34:39 INFO mapred.JobClient: Running job: job_201303011732_0001
13/03/01 17:34:40 INFO mapred.JobClient:  map 0% reduce 0%
13/03/01 17:34:45 INFO mapred.JobClient:  map 10% reduce 0%
13/03/01 17:34:46 INFO mapred.JobClient:  map 20% reduce 0%
13/03/01 17:34:49 INFO mapred.JobClient:  map 40% reduce 0%
13/03/01 17:34:52 INFO mapred.JobClient:  map 60% reduce 0%
13/03/01 17:34:54 INFO mapred.JobClient:  map 60% reduce 10%
13/03/01 17:34:55 INFO mapred.JobClient:  map 80% reduce 10%
13/03/01 17:34:57 INFO mapred.JobClient:  map 100% reduce 20%
13/03/01 17:35:00 INFO mapred.JobClient:  map 100% reduce 33%
13/03/01 17:35:02 INFO mapred.JobClient:  map 100% reduce 100%
13/03/01 17:35:03 INFO mapred.JobClient: Job complete: job_201303011732_0001
13/03/01 17:35:03 INFO mapred.JobClient: Counters: 27
13/03/01 17:35:03 INFO mapred.JobClient:   Job Counters 
13/03/01 17:35:03 INFO mapred.JobClient:     Launched reduce tasks=1
13/03/01 17:35:03 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=29317
13/03/01 17:35:03 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
13/03/01 17:35:03 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
13/03/01 17:35:03 INFO mapred.JobClient:     Launched map tasks=10
13/03/01 17:35:03 INFO mapred.JobClient:     Data-local map tasks=10
13/03/01 17:35:03 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=16443
13/03/01 17:35:03 INFO mapred.JobClient:   File Input Format Counters 
13/03/01 17:35:03 INFO mapred.JobClient:     Bytes Read=1180
13/03/01 17:35:03 INFO mapred.JobClient:   File Output Format Counters 
13/03/01 17:35:03 INFO mapred.JobClient:     Bytes Written=97
13/03/01 17:35:03 INFO mapred.JobClient:   FileSystemCounters
13/03/01 17:35:03 INFO mapred.JobClient:     FILE_BYTES_READ=226
13/03/01 17:35:03 INFO mapred.JobClient:     HDFS_BYTES_READ=2400
13/03/01 17:35:03 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=264981
13/03/01 17:35:03 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=215
13/03/01 17:35:03 INFO mapred.JobClient:   Map-Reduce Framework
13/03/01 17:35:03 INFO mapred.JobClient:     Map output materialized bytes=280
13/03/01 17:35:03 INFO mapred.JobClient:     Map input records=10
13/03/01 17:35:03 INFO mapred.JobClient:     Reduce shuffle bytes=280
13/03/01 17:35:03 INFO mapred.JobClient:     Spilled Records=40
13/03/01 17:35:03 INFO mapred.JobClient:     Map output bytes=180
13/03/01 17:35:03 INFO mapred.JobClient:     Total committed heap usage (bytes)=1931190272
13/03/01 17:35:03 INFO mapred.JobClient:     Map input bytes=240
13/03/01 17:35:03 INFO mapred.JobClient:     Combine input records=0
13/03/01 17:35:03 INFO mapred.JobClient:     SPLIT_RAW_BYTES=1220
13/03/01 17:35:03 INFO mapred.JobClient:     Reduce input records=20
13/03/01 17:35:03 INFO mapred.JobClient:     Reduce input groups=20
13/03/01 17:35:03 INFO mapred.JobClient:     Combine output records=0
13/03/01 17:35:03 INFO mapred.JobClient:     Reduce output records=0
13/03/01 17:35:03 INFO mapred.JobClient:     Map output records=20
Job Finished in 24.631 seconds
Estimated value of Pi is 3.14800000000000000000


ps ax | grep hadoop | wc -l
# expected output is 6</code></pre>
</div>
    
</body>
</html>
